---
title: C-1.Spark核心集群概念.md
weblog_mt_keywords: "概念"
---

|  术语   |   解释  |   备注  |
| --- | --- | --- |
| Application    |用户在spark上构建的程序，包含了driver程序以及集群上的executors。     | -    |
|Driver Program  | 运行main函数并创建SparkContext的程序。<br>客户端的应用程序，Driver Program类似于hadoop的wordcount程序的main函数。    |  -   |
|Clust Manager  | 集群的资源管理器，在集群上获取资源的外部服务。Such as Standalone,Mesos,Yarn.<br> 拿Yarn为例，客户端程序会向Yarn申请计算我这个任务需要多少内存，几个CPU，ect。然后Clust Manager通过调度告诉客户端可以使用，然后客户端就可以把程序送到每个worker node上面执行   |  -   |
|Worker Node     | 集群中任何一个可以运行spark应用代码的节点。<br> Worker Node是物理节点，可以在上面启动Executor进程   |  -   |
| Executor    |  在每个WorkerNode上为某应用启动的进程，该进程负责运行任务，并负责将数据存在内存或者磁盘上，每个任务都有各自独立的Executor。<br> Executor是一个执行Task的容器。它的主要职责是：<br> 1.初始化程序要执行的上下文SparkEnv，解决应用程序需要运行时的jar包的依赖，加载类。<br> 
2.同时还有一个ExecutorBackend向cluster manager汇报当前的任务状态，这一方面有点类似hadoop的tasktracker和task。<br> 总结：Executor是一个应用程序运行的监控和执行容器。| -    |
|Job     | 包含很多task的并行计算，可以认为是Spark RDD里面的action，每个action的计算会生成一个job。<br> 用户提交的Job会提交给DAGScheduler，Job会被分解成Stage和Task。    | -    |
|Stage     |  一个Job会被拆分为多组Task，每组任务被称为一个Stage就像Map Stage，Reduce Stage。<br> 
Stage的划分在RDD的论文中有详细介绍，简单的说是以shuffle和result这两种类型来划分，在Spark中有两类task，一类是shuffleMapTask，一类是resultTask，第一类task的输出是shuffle所需数据，第二类task的输出是result，stage的划分也以此为依据，shuffle之前的所有变换是一个stage，shuffle之后的操作是另一个stage。比如rdd.parallize(1 to 10).freach(println)这个操作没有shuffle，直接输出，那么只有它的task是resultTask，stage也只有一个；如果是rdd.map(x=>(x,1)).reduceByKey(_+_).foreach(println),这个job因为有reduce，所以有一个shuffle过程，那么reduceByKey之前的是一个stage，执行shuffleMapTask，输出shuffle所需数据，reduceByKey到最后是一个stage，直接就输出结果。如果job中有多次shuffl，e那么每个shuffle之前都是一个stage。|-     |
| Task    | 被送到executor上的工作单元。<br> Spark上分为2类task。<br> 1.ShuffleMapTask<br> * A ShuffleMapTask divides the elements of an RDD into multiple buckets(based on a partitioner specified in the ShuffleDenpency)<br> 2.resultTask<br> * A task that sends back the output to the drive application  | -    |
| Partition    | Partition 类似hadoop的Split，计算是以partition为单元进行的，当然partition的划分依据有很多，这可以自己定义的，像HDFS文件，划分方式就和MapReduce一样，以文件的block来划分不同的partition。总而言之，Spark的partition在概念上与hadoop中的split是相似的，提供了一种划分数据的方式。    | -    |
|  Deply mode   | 部署模式    | -    |

































