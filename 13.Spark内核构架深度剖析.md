---
title: 13.Spark内核构架深度剖析
weblog_mt_keywords: "标签1,标签2"
---
[toc]

# spark核心架构


1、Application
2、spark-submit
3、Driver
4、SparkContext
5、Master
6、Worker
7、Executor
8、Job
9、DAGScheduler
10、TaskScheduler
11、ShufieMap Task and ResultTask

![13-1 Spark核心架构](https://github.com/2415970940/save_img/raw/master/spark/13/13-1.jpg)

![13-2 Spark核心架构流程](https://github.com/2415970940/save_img/raw/master/spark/13/13-2.png)
对于13-2图流程详解
Spark任务简介：
Spark-submit—>SparkSubmit–>main–>submit–>doRunMain–>RunMain–>通过反射创建我们编写的主类的实例对象，调用main方法–>开始执行我们编写的代码–>初始化SparkContext对象–>创建初始的RDD–>触发action算子–>提交job–>worker执行任务–>任务结束

Spark任务详解：
1）、将我们编写的程序打成jar包

2）、调用spark-submit脚本提交任务到集群上运行

3）、运行sparkSubmit的main方法，在这个方法中通过反射的方式创建我们编写的主类的实例对象，然后调用main方法，开始执行我们的代码（注意，我们的spark程序中的driver就运行在sparkSubmit进程中）

4）、当代码运行到创建SparkContext对象时，那就开始初始化SparkContext对象了

5）、在初始化SparkContext对象的时候，会创建两个特别重要的对象，分别是：DAGScheduler
和TaskScheduler

【DAGScheduler的作用】将RDD的依赖切分成一个一个的stage，然后将stage作为taskSet提交给DriverActor

6）、在构建taskScheduler的同时，会创建两个非常重要的对象，分别是DriverActor和ClientActor

【clientActor的作用】向master注册用户提交的任务
【DriverActor的作用】接受executor的反向注册，将任务提交给executor

7）、当clientActor启动后，会将用户提交的任务和相关的参数封装到ApplicationDescription对象中，然后提交给master进行任务的注册

8）、当master接受到clientActor提交的任务请求时，会将请求参数进行解析，并封装成Application，然后将其持久化，然后将其加入到任务队列waitingApps中

9）、当轮到我们提交的任务运行时，就开始调用schedule()，进行任务资源的调度

10）、master将调度好的资源封装到launchExecutor中发送给指定的worker

11）、worker接受到Maseter发送来的launchExecutor时，会将其解压并封装到ExecutorRunner中，然后调用这个对象的start(), 启动Executor

12）、Executor启动后会向DriverActor进行反向注册

13）、driverActor会发送注册成功的消息给Executor

14）、Executor接受到DriverActor注册成功的消息后会创建一个线程池，用于执行DriverActor发送过来的task任务

15）、当属于这个任务的所有的Executor启动并反向注册成功后，就意味着运行这个任务的环境已经准备好了，driver会结束SparkContext对象的初始化，也就意味着new SparkContext这句代码运行完成

16）、当初始化sc成功后，driver端就会继续运行我们编写的代码，然后开始创建初始的RDD，然后进行一系列转换操作，当遇到一个action算子时，也就意味着触发了一个job

17）、driver会将这个job提交给DAGScheduler

18）、DAGScheduler将接受到的job，从最后一个算子向前推导，将DAG依据宽依赖划分成一个一个的stage，然后将stage封装成taskSet，并将taskSet中的task提交给DriverActor

19）、DriverActor接受到DAGScheduler发送过来的task，会拿到一个序列化器，对task进行序列化，然后将序列化好的task封装到launchTask中，然后将launchTask发送给指定的Executor

20）、Executor接受到了DriverActor发送过来的launchTask时，会拿到一个反序列化器，对launchTask进行反序列化，封装到TaskRunner中，然后从Executor这个线程池中获取一个线程，将反序列化好的任务中的算子作用在RDD对应的分区上

# 宽依赖与窄依赖

* 窄依赖是指父RDD的每个分区只被子RDD的一个分区所使用，子RDD分区通常对应常数个父RDD分区(O(1)，与数据规模无关) 相应的，
* 宽依赖是指父RDD的每个分区都可能被多个子RDD分区所使用，子RDD分区通常对应所有的父RDD分区(O(n)，与数据规模有关

宽依赖和窄依赖如下图所示：

![13-3 窄依赖与宽依赖](https://github.com/2415970940/save_img/raw/master/spark/13/13-3.png)

相比于宽依赖，窄依赖对优化很有利 ，主要基于以下两点：
- 1.宽依赖往往对应着shuffle操作，需要在运行过程中将同一个父RDD的分区传入到不同的子RDD分区中，中间可能涉及多个节点之间的数据传输；而窄依赖的每个父RDD的分区只会传入到一个子RDD分区中，通常可以在一个节点内完成转换。 
- 2.当RDD分区丢失时（某个节点故障），spark会对数据进行重算。
 	- 对于窄依赖，由于父RDD的一个分区只对应一个子RDD分区，这样只需要重算和子RDD分区对应的父RDD分区即可，所以这个重算对数据的利用率是100%的； 
	- 对于宽依赖，重算的父RDD分区对应多个子RDD分区，这样实际上父RDD 中只有一部分的数据是被用于恢复这个丢失的子RDD分区的，另一部分对应子RDD的其它未丢失分区，这就造成了多余的计算；更一般的，宽依赖中子RDD分区通常来自多个父RDD分区，极端情况下，所有的父RDD分区都要进行重新计算。 
	- 如下图所示，b1分区丢失，则需要重新计算a1,a2和a3，这就产生了冗余计算(a1,a2,a3中对应b2的数据)。
![13-4](https://github.com/2415970940/save_img/raw/master/spark/13/13-4.png)
窄依赖的函数有：map, filter, union, join(父RDD是hash-partitioned ), mapPartitions, mapValues
宽依赖的函数有：groupByKey, join(父RDD不是hash-partitioned ), partitionBy

![13-5 窄依赖与宽依赖深入剖析](https://github.com/2415970940/save_img/raw/master/spark/13/13-5.png)

# Spark提交模式
1、Spark内核架构,其实就是第一种模式,standalone模式,基于Spark自己的Master-Worker集群。

2、第二种,是基于YARN的yarn-cluster模式。

3、第三种,是基于YARN的yarn-client模式。

4、如果,你要切换到第二种和第三种模式,很简单,将我们之前用于提交spark应用程序的spark-submit脚本,加上--master参数,设置为yarn-cluster,或yarn-client,即可。如果你没设置,那么,就是standalone模式。
## Spark Standalone
 Standalone模式是Spark实现的资源调度框架，其主要的节点有Client节点、Master节点和Worker节点。其中Driver既可以运行在Master节点上中，也可以运行在本地Client端。当用spark-shell交互式工具提交Spark的Job时，Driver在Master节点上运行；当使用spark-submit工具提交Job或者在Eclips、IDEA等开发平台上使用”new SparkConf.setManager(“spark://master:7077”)”方式运行Spark任务时，Driver是运行在本地Client端上的。
 
![13-6 standalone示意图](https://github.com/2415970940/save_img/raw/master/spark/13/13-6.png)

其运行过程如下：

*    1.SparkContext连接到Master，向Master注册并申请资源（CPU Core 和Memory）；

*    2.Master根据SparkContext的资源申请要求和Worker心跳周期内报告的信息决定在哪个Worker上分配资源，然后在该Worker上获取资源，然后启动StandaloneExecutorBackend；

*    3.StandaloneExecutorBackend向SparkContext注册；

*    4.SparkContext将Applicaiton代码发送给StandaloneExecutorBackend；并且SparkContext解析Applicaiton代码，构建DAG图，并提交给DAG Scheduler分解成Stage（当碰到Action操作时，就会催生Job；每个Job中含有1个或多个Stage，Stage一般在获取外部数据和shuffle之前产生），然后以Stage（或者称为TaskSet）提交给Task Scheduler，Task Scheduler负责将Task分配到相应的Worker，最后提交给StandaloneExecutorBackend执行；

*    5.StandaloneExecutorBackend会建立Executor线程池，开始执行Task，并向SparkContext报告，直至Task完成。

*    6.所有Task完成后，SparkContext向Master注销，释放资源。

## Spark On Yarn
 YARN是一种统一资源管理机制，在其上面可以运行多套计算框架。目前的大数据技术世界，大多数公司除了使用Spark来进行数据计算，由于历史原因或者单方面业务处理的性能考虑而使用着其他的计算框架，比如MapReduce、Storm等计算框架。Spark基于此种情况开发了Spark on YARN的运行模式，由于借助了YARN良好的弹性资源管理机制，不仅部署Application更加方便，而且用户在YARN集群中运行的服务和Application的资源也完全隔离，更具实践应用价值的是YARN可以通过队列的方式，管理同时运行在集群中的多个服务。

Spark on YARN模式根据Driver在集群中的位置分为两种模式：一种是YARN-Client模式，另一种是YARN-Cluster（或称为YARN-Standalone模式）。
### 1：Yarn框架流程

   任何框架与YARN的结合，都必须遵循YARN的开发模式。在分析Spark on YARN的实现细节之前，有必要先分析一下YARN框架的一些基本原理。Yarn框架的基本流程如下：
![13-7](https://github.com/2415970940/save_img/raw/master/spark/13/13-7.png)   
其中，ResourceManager负责将集群的资源分配给各个应用使用，而资源分配和调度的基本单位是Container，其中封装了机器资源，如内存、CPU、磁盘和网络等，每个任务会被分配一个Container，该任务只能在该Container中执行，并使用该Container封装的资源。NodeManager是一个个的计算节点，主要负责启动Application所需的Container，监控资源（内存、CPU、磁盘和网络等）的使用情况并将之汇报给ResourceManager。ResourceManager与NodeManagers共同组成整个数据计算框架，ApplicationMaster与具体的Application相关，主要负责同ResourceManager协商以获取合适的Container，并跟踪这些Container的状态和监控其进度。

### 2：Yarn Client模式 
Yarn-Client模式中，Driver在客户端本地运行，这种模式可以使得Spark Application和客户端进行交互，因为Driver在客户端，所以可以通过webUI访问Driver的状态，默认是http://hadoop1:4040 访问，而YARN通过http:// hadoop1:8088访问。

  YARN-client的工作流程分为以下几个步骤：
 ![13-8](https://github.com/2415970940/save_img/raw/master/spark/13/13-8.png)

* (1).Spark Yarn Client向YARN的ResourceManager申请启动Application Master。同时在SparkContent初始化中将创建DAGScheduler和TASKScheduler等，由于我们选择的是Yarn-Client模式，程序会选择YarnClientClusterScheduler和YarnClientSchedulerBackend；

* (2).ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，与YARN-Cluster区别的是在该ApplicationMaster不运行SparkContext，只与SparkContext进行联系进行资源的分派；

* (3).Client中的SparkContext初始化完毕后，与ApplicationMaster建立通讯，向ResourceManager注册，根据任务信息向ResourceManager申请资源（Container）；

*  (4).一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container中启动启动CoarseGrainedExecutorBackend，CoarseGrainedExecutorBackend启动后会向Client中的SparkContext注册并申请Task；

* (5).Client中的SparkContext分配Task给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向Driver汇报运行的状态和进度，以让Client随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务；
*  (6).应用程序运行完成后，Client的SparkContext向ResourceManager申请注销并关闭自己

###  3：Spark Cluster模式

 在YARN-Cluster模式中，当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：第一个阶段是把Spark的Driver作为一个ApplicationMaster在YARN集群中先启动；第二个阶段是由ApplicationMaster创建应用程序，然后为它向ResourceManager申请资源，并启动Executor来运行Task，同时监控它的整个运行过程，直到运行完成。

 YARN-cluster的工作流程分为以下几个步骤：
![13-9](https://github.com/2415970940/save_img/raw/master/spark/13/13-9.png)       

* (1).   Spark Yarn Client向YARN中提交应用程序，包括ApplicationMaster程序、启动ApplicationMaster的命令、需要在Executor中运行的程序等；

* (2).   ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，其中ApplicationMaster进行SparkContext等的初始化；

* (3).   ApplicationMaster向ResourceManager注册，这样用户可以直接通过ResourceManage查看应用程序的运行状态，然后它将采用轮询的方式通过RPC协议为各个任务申请资源，并监控它们的运行状态直到运行结束；

* (4).   一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container中启动启动CoarseGrainedExecutorBackend，CoarseGrainedExecutorBackend启动后会向ApplicationMaster中的SparkContext注册并申请Task。这一点和Standalone模式一样，只不过SparkContext在Spark Application中初始化时，使用CoarseGrainedSchedulerBackend配合YarnClusterScheduler进行任务的调度，其中YarnClusterScheduler只是对TaskSchedulerImpl的一个简单包装，增加了对Executor的等待逻辑等；

* (5).   ApplicationMaster中的SparkContext分配Task给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向ApplicationMaster汇报运行的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务；

* (6).   应用程序运行完成后，ApplicationMaster向ResourceManager申请注销并关闭自己。

### 4：Spark Client 和 Spark Cluster的区别
![13-10](https://github.com/2415970940/save_img/raw/master/spark/13/13-10.png)

理解YARN-Client和YARN-Cluster深层次的区别之前先清楚一个概念：Application Master。在YARN中，每个Application实例都有一个ApplicationMaster进程，它是Application启动的第一个容器。它负责和ResourceManager打交道并请求资源，获取资源之后告诉NodeManager为其启动Container。从深层次的含义讲YARN-Cluster和YARN-Client模式的区别其实就是ApplicationMaster进程的区别。

*   YARN-Cluster模式下，Driver运行在AM(Application Master)中，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行，因而YARN-Cluster模式不适合运行交互类型的作业；

*  YARN-Client模式下，Application Master仅仅向YARN请求Executor，Client会和请求的Container通信来调度他们工作，也就是说Client不能离开。

补充：在standalone模式转为yarn模式，要在spark安装目录下改个配置
vi /usr/local/spark/conf/spark-env.sh
添加hadoop 
export HADOOP_HOME=/usr/local/hadoop

# SparkContext原理剖析
![13-11 SparkContext原理剖析](https://github.com/2415970940/save_img/raw/master/spark/13/13-11.png)
SparkContext.scala
```scala
...
// Create and start the scheduler
private[spark] var (schedulerBackend, taskScheduler) =
    SparkContext.createTaskScheduler(this, master)
	
@volatile private[spark] var dagScheduler: DAGScheduler = _ //DAGScheduler.scala
...	
//createTaskScheduler方法
private def createTaskScheduler(
      sc: SparkContext,
      master: String): (SchedulerBackend, TaskScheduler) = {
	  	master match {
		//standalone模式
			case SPARK_REGEX(sparkUrl) =>
				val scheduler = new TaskSchedulerImpl(sc)
				val masterUrls = sparkUrl.split(",").map("spark://" + _)
				val backend = new SparkDeploySchedulerBackend(scheduler, sc, masterUrls)
				scheduler.initialize(backend)
				(backend, scheduler)
				}
...				
//createTaskScheduler方法执行完后
taskScheduler.start() //TaskSchedulerImpl.scala的start（）方法
...
```


TaskSchedulerImpl.scala
```scala
/*TaskSchedulerImpl的实现
*1、底层通过操作一个SchedulerBackend，针对不同种类的cluster（standalone、yarn、mesos），调度task
*2、它也可以通过使用一个LocalBackend，并将isLocal参数设置为true，来在本地模式下工作
*3、它负责处理一些通用的逻辑，比如说决定多个job的顺序，启动推测任务执行
*4、客户端首先应用调用它的initialize（）方法和start（）方法，然后通过runTasks（）方法提交task sets
/
/**
 * Schedules tasks for multiple types of clusters by acting through a SchedulerBackend.
 * It can also work with a local setup by using a LocalBackend and setting isLocal to true.
 * It handles common logic, like determining a scheduling order across jobs, waking up to launch
 * speculative tasks, etc.
 *
 * Clients should first call initialize() and start(), then submit task sets through the
 * runTasks method.
 *
 * THREADING: SchedulerBackends and task-submitting clients can call this class from multiple
 * threads, so it needs locks in public API methods to maintain its state. In addition, some
 * SchedulerBackends synchronize on themselves when they want to send events here, and then
 * acquire a lock on us, so we need to make sure that we don't try to lock the backend while
 * we are holding a lock on ourselves.
 */
 
 ...
   def initialize(backend: SchedulerBackend) {
    this.backend = backend
    // temporarily set rootPool name to empty
    rootPool = new Pool("", schedulingMode, 0, 0)
    schedulableBuilder = {
      schedulingMode match {
        case SchedulingMode.FIFO =>
          new FIFOSchedulableBuilder(rootPool)
        case SchedulingMode.FAIR =>
          new FairSchedulableBuilder(rootPool, conf)
      }
    }
...	
 override def start() {
    backend.start()//SparkDeploySchedulerBackend.scala的start（）方法

    if (!isLocal && conf.getBoolean("spark.speculation", false)) {
      logInfo("Starting speculative execution thread")
      import sc.env.actorSystem.dispatcher
      sc.env.actorSystem.scheduler.schedule(SPECULATION_INTERVAL milliseconds,
            SPECULATION_INTERVAL milliseconds) {
        Utils.tryOrExit { checkSpeculatableTasks() }
      }
    }
  }
  ...
```

SparkDeploySchedulerBackend.scala
```scala
...
override def start() {
    super.start()
	...
	// ApplicationDescription非常重要，设置运行脚本的信息
	//Application需要多少cpu core，每个slave需要多少内存
	val appDesc = new ApplicationDescription(sc.appName, maxCores, sc.executorMemory, command,
      appUIAddress, sc.eventLogDir, sc.eventLogCodec)
	  //创建AppClient
	client = new AppClient(sc.env.actorSystem, masters, appDesc, this, conf)//AppClient.scala
    client.start()
	  ...
	}
...
```
AppClient.scala
```scala
/*它是一个接口
*它负责为application与spark集群通信
*它会接收spark master的url，以及一个ApplicationDescription，和一个集群事件的监听器，以及各种事件发生时，监听器的回调函数
*
*/
/**
 * Interface allowing applications to speak with a Spark deploy cluster. Takes a master URL,
 * an app description, and a listener for cluster events, and calls back the listener when various
 * events occur.
 *
 * @param masterUrls Each url should look like spark://host:port.
 */
 ...
 def start() {
    // Just launch an actor; it will call back into the listener.
    actor = actorSystem.actorOf(Props(new ClientActor))
  }
  ...
  //ClientActor是AppClient的内部类
  class ClientActor extends Actor with ActorLogReceive with Logging{
  ...
     def tryRegisterAllMasters() {
      for (masterAkkaUrl <- masterAkkaUrls) {
        logInfo("Connecting to master " + masterAkkaUrl + "...")
        val actor = context.actorSelection(masterAkkaUrl)
        actor ! RegisterApplication(appDescription)
      }
    }

    def registerWithMaster() {
      tryRegisterAllMasters()
      import context.dispatcher
      var retries = 0
      registrationRetryTimer = Some {
        context.system.scheduler.schedule(REGISTRATION_TIMEOUT, REGISTRATION_TIMEOUT) {
          Utils.tryOrExit {
            retries += 1
            if (registered) {
              registrationRetryTimer.foreach(_.cancel())
            } else if (retries >= REGISTRATION_RETRIES) {
              markDead("All masters are unresponsive! Giving up.")
            } else {
              tryRegisterAllMasters()
            }
          }
        }
      }
  }
  ...
```

/DAGScheduler.scala

``` scala
/*实现了面向stage的调度机制的高层次的调度层，它会为每个job计算一个stage的DGA（有向无环图），追踪RDD和stage的输出是否被物化（物化就是说写入磁盘或内存地方），并且寻找最小调度机制（最优）来运行job
*它会将stage作为tasksets提交到底层的TaskSchedulerImpl，来在集群上运行他们（task）。
*
*除了处理stage的DAG，它还负责决定运行每个task的最佳位置，基于当前缓存状态，将这些最佳位置提交给底层的TaskSchedulerImpl，此外，它还会处理由于shuffle输出文件丢失导致的失败，在这种情况下，旧的stage被重新提交。
一个stage内部的失败，如果不是由于shuffle输出文件丢失导致的失败，会被TaskScheduler处理，它会多次重试每个task，直到最后，会取消这个stage。
*/
/**
 * The high-level scheduling layer that implements stage-oriented scheduling. It computes a DAG of
 * stages for each job, keeps track of which RDDs and stage outputs are materialized, and finds a
 * minimal schedule to run the job. It then submits stages as TaskSets to an underlying
 * TaskScheduler implementation that runs them on the cluster.
 *
 * In addition to coming up with a DAG of stages, this class also determines the preferred
 * locations to run each task on, based on the current cache status, and passes these to the
 * low-level TaskScheduler. Furthermore, it handles failures due to shuffle output files being
 * lost, in which case old stages may need to be resubmitted. Failures *within* a stage that are
 * not caused by shuffle file loss are handled by the TaskScheduler, which will retry each task
 * a small number of times before cancelling the whole stage.
 *
 * Here's a checklist to use when making or reviewing changes to this class:
 *
 *  - When adding a new data structure, update `DAGSchedulerSuite.assertDataStructuresEmpty` to
 *    include the new structure. This will help to catch memory leaks.
 */
```
# Master原理剖析和源码分析

1、主备切换机制原理剖析
2、注册机制原理剖析与源码分析
3、状态改变机制源码分析
4、资源调度机制源码分析（两种资源调度算法）

## 主备切换机制原理剖析

Spark Master主备切换主要有两种机制，之中是基于文件系统，一种是基于Zookeeper.基于文件系统的主备切换机制需要在Active Master挂掉后手动切换到Standby Master上，而基于Zookeeper的主备切换机制可以实现自动切换Master。

切换流程图
![13-12]()
![13-13]()

流程说明：

Standby Master模式

1. 使用持久化引擎读取持久化的storeApps、storeDrivers、storeWorkers，持久化引擎有FileSystemPersistenceEngine和ZookeeperPersistenceEngine

2. 判读如果storedApps、storedDrivers、store的Workers有任何一个非空就继续向后执行.

3. 持久化引擎的Application、Driver、Worker的信息重新注册到Master内部的内存缓存结构中

4. 将Application和Worker的状态都修改为UNKONWN,然后向Application所对应的Driver及Worker发送Standby Master的地址

5. Driver和Worker在接收到Master发送的地址后，返回响应消息给新的Master

6. Master在陆续收到Driver和Worker发送来的响应消息后，会使用completeRecovery()方法对没有发生响应消息的Driver和Worker进行处理，过滤掉它们的信息。

7. 最后调用Master的schedule()方法，对正在等待资源调度的Driver和Application进行调度，比如在某个Worker上启动Driver或者为Application在Worker上启动它的Executor.

源码分析

创建持久化引擎

入口文件包名：org.apache.spark.deploy.master

创建持久化引擎在preStart()方法中，通过spark.deploy.recoveryMode配置参数确定持久化引擎的类别，缺省值为none.

``` scala
val (persistenceEngine_, leaderElectionAgent_) = RECOVERY_MODE match {
      case "ZOOKEEPER" =>
        logInfo("Persisting recovery state to ZooKeeper")
        val zkFactory =
          new ZooKeeperRecoveryModeFactory(conf, SerializationExtension(context.system))
        (zkFactory.createPersistenceEngine(), zkFactory.createLeaderElectionAgent(this))
      case "FILESYSTEM" =>
        val fsFactory =
          new FileSystemRecoveryModeFactory(conf, SerializationExtension(context.system))
        (fsFactory.createPersistenceEngine(), fsFactory.createLeaderElectionAgent(this))
      case "CUSTOM" =>
        val clazz = Class.forName(conf.get("spark.deploy.recoveryMode.factory"))
        val factory = clazz.getConstructor(classOf[SparkConf], classOf[Serialization])
          .newInstance(conf, SerializationExtension(context.system))
          .asInstanceOf[StandaloneRecoveryModeFactory]
        (factory.createPersistenceEngine(), factory.createLeaderElectionAgent(this))
      case _ =>
        (new BlackHolePersistenceEngine(), new MonarchyLeaderAgent(this))
    }
    persistenceEngine = persistenceEngine_
    leaderElectionAgent = leaderElectionAgent_
```
持久化数据的处理

``` scala
override def receiveWithLogging = {
    case ElectedLeader => {
	//读取持久化信息
      val (storedApps, storedDrivers, storedWorkers) = persistenceEngine.readPersistedData()
      state = if (storedApps.isEmpty && storedDrivers.isEmpty && storedWorkers.isEmpty) {
        RecoveryState.ALIVE
      } else {
        RecoveryState.RECOVERING
      }
      logInfo("I have been elected leader! New state: " + state)
      if (state == RecoveryState.RECOVERING) {
	  //注册持久化信息，向Driver和Worker发送Master信息
        beginRecovery(storedApps, storedDrivers, storedWorkers)
		//对没有向发送相应信息的Driver和Worker进行处理
        recoveryCompletionTask = context.system.scheduler.scheduleOnce(WORKER_TIMEOUT millis, self,
          CompleteRecovery)
      }
    }
```

completeRecovery方法分析
功能：

将Application和Worker过滤出来目前的状态，如果是UNKNOWN的进行遍历，分别调用removeWorker和finishApplication方法，对可能已经故障或者已经死掉的Application和Worker进行清理。

清理过程：1、从内存缓存结构中移除。2、从相关的组件的内存中移除。3、从持久化存储中移除。

``` scala
  def completeRecovery() {
    // Ensure "only-once" recovery semantics using a short synchronization period.
    synchronized {
      if (state != RecoveryState.RECOVERING) { return }
      state = RecoveryState.COMPLETING_RECOVERY
    }

    // Kill off any workers and apps that didn't respond to us.
	//Worker的过滤
    workers.filter(_.state == WorkerState.UNKNOWN).foreach(removeWorker)
	//Application的过滤
    apps.filter(_.state == ApplicationState.UNKNOWN).foreach(finishApplication)

    // Reschedule drivers which were not claimed by any workers
	//数据清理
    drivers.filter(_.worker.isEmpty).foreach { d =>
      logWarning(s"Driver ${d.id} was not found after master recovery")
      if (d.desc.supervise) {
        logWarning(s"Re-launching ${d.id}")
        relaunchDriver(d)
      } else {
        removeDriver(d.id, DriverState.ERROR, None)
        logWarning(s"Did not re-launch ${d.id} because it was not supervised")
      }
    }

    state = RecoveryState.ALIVE
    schedule()
    logInfo("Recovery complete - resuming operations!")
  }
```
## Master注册机制和状态改变机制
![13-14 ]()
![13-15 ]()

注册机制源码说明：

入口：org.apache.spark.deploy.master文件下的receiveWithLogging方法中的case RegisterApplication(注册Application)、case RegisterWorker(注册Worker)、case RequestSubmitDriver(注册Driver).

``` scala
private[spark] class Master(
    host: String,
    port: Int,
    webUiPort: Int,
    val securityMgr: SecurityManager,
    val conf: SparkConf)
  extends Actor with ActorLogReceive with Logging with LeaderElectable {
  ...
  override def receiveWithLogging = {
  ...
      case RegisterApplication(description) => {
	  //Master是standby master，请求Application注册什么都不做
		  if (state == RecoveryState.STANDBY) {
			// ignore, don't send response
		  } else {
			logInfo("Registering app " + description.name)
			//用ApplicationDescription信息，创建ApplicationInfo
			val app = createApplication(description, sender)
			//注册Application
			//将ApplicationInfo加入缓存，将Application加入等待的队列——waitingApps
			registerApplication(app)
			logInfo("Registered app " + description.name + " with ID " + app.id)
			//使用持久化引擎，将ApplicationInfo进行持久化
			persistenceEngine.addApplication(app)
			//反向，向SparkDeploySchedulerBackend的AppClient的ClientActor，发送消息，也就是 RegisteredApplication，不是 RegisterApplication
			sender ! RegisteredApplication(app.id, masterUrl)
			schedule()
		  }
   	 }
	 ...
	}
  ...
    def createApplication(desc: ApplicationDescription, driver: ActorRef): ApplicationInfo = {
    val now = System.currentTimeMillis()
    val date = new Date(now)
    new ApplicationInfo(now, newApplicationId(date), desc, date, driver, defaultCores)
  }
  ...
    def registerApplication(app: ApplicationInfo): Unit = {
		val appAddress = app.driver.path.address
		if (addressToApp.contains(appAddress)) {
		  logInfo("Attempted to re-register application at same address: " + appAddress)
		  return
		}
		//将APP的信息加入内存缓存中
		applicationMetricsSystem.registerSource(app.appSource)
		apps += app
		idToApp(app.id) = app
		actorToApp(app.driver) = app
		addressToApp(appAddress) = app
		//将APP加入等待调入的队列
		waitingApps += app
	  }
  ...
```
## 状态改变机制源码分析
入口：org.apache.spark.deploy.master文件下的receiveWithLogging方法中的DriverStateChanged(Driver状态改变处理)、ExecutorStateChanged（Executor状态改变处理）。

状态改变处理流程图
![13-16 ]()

``` scala
    case DriverStateChanged(driverId, state, exception) => {
	//如果driver的状态是错误，完成，被杀掉，失败，就移除driver
      state match {
        case DriverState.ERROR | DriverState.FINISHED | DriverState.KILLED | DriverState.FAILED =>
          removeDriver(driverId, state, exception)
        case _ =>
          throw new Exception(s"Received unexpected state update for driver $driverId: $state")
      }
    }
```

```scala
def removeDriver(driverId: String, finalState: DriverState, exception: Option[Exception]) {
//用scala的find()高阶函数,找到driveId对应的driver
    drivers.find(d => d.id == driverId) match {
	//找到
      case Some(driver) =>
        logInfo(s"Removing driver: $driverId")
		//从内存清除
        drivers -= driver
        if (completedDrivers.size >= RETAINED_DRIVERS) {
          val toRemove = math.max(RETAINED_DRIVERS / 10, 1)
          completedDrivers.trimStart(toRemove)
        }
		//向completedDrivers中加入driver
        completedDrivers += driver
		//使用持久化引擎去除driver的持久化信息
        persistenceEngine.removeDriver(driver)
		//设置driver的state，exception
        driver.state = finalState
        driver.exception = exception
		//将driver所在的worker，移除driver
        driver.worker.foreach(w => w.removeDriver(driver))
		//调用 schedule()
        schedule()
      case None =>
        logWarning(s"Asked to remove unknown driver: $driverId")
    }
  }
```

```scala
case ExecutorStateChanged(appId, execId, state, message, exitStatus) => {
//找到executor对应的app，然后再反过来通过app内部的executors缓存获取executer信息
      val execOption = idToApp.get(appId).flatMap(app => app.executors.get(execId))
      execOption match {
        case Some(exec) => {
		//设置executor的当前状态
          val appInfo = idToApp(appId)
          exec.state = state
          if (state == ExecutorState.RUNNING) { appInfo.resetRetryCount() }
		  //向driver同步发送ExecutorUpdated消息
          exec.application.driver ! ExecutorUpdated(execId, state, message, exitStatus)
          if (ExecutorState.isFinished(state)) {
            // Remove this executor from the worker and app
            logInfo(s"Removing executor ${exec.fullId} because it is $state")
			//从app的缓存中移除executor
            appInfo.removeExecutor(exec)
			//从运行executor的worker中移除executor
            exec.worker.removeExecutor(exec)
            val normalExit = exitStatus == Some(0)
            // Only retry certain number of times so we don't go into an infinite loop.
			//退出状态非正常的
            if (!normalExit) {
			//判断application当前的重试次数，是否达到了最大值
              if (appInfo.incrementRetryCount() < ApplicationState.MAX_NUM_RETRY) {
               //重新调度
			   schedule()
              } else {
			  //否则那么就进行removeApplication操作
                val execs = appInfo.executors.values
                if (!execs.exists(_.state == ExecutorState.RUNNING)) {
                  logError(s"Application ${appInfo.desc.name} with ID ${appInfo.id} failed " +
                    s"${appInfo.retryCount} times; removing it")
                  removeApplication(appInfo, ApplicationState.FAILED)
                }
              }
            }
          }
        }
        case None =>
          logWarning(s"Got status update for unknown executor $appId/$execId")
      }
    }
```
## 资源调度机制源码分析
在Master类中的schedule方法是master的主要的资源调度的方法
首先是对driver进行调度

``` scala
private def schedule() {
// 判断master状态，不为ALIVE时直接返回
    if (state != RecoveryState.ALIVE) { return }

    // First schedule drivers, they take strict precedence over applications
    // Randomization helps balance drivers
	// 获取状态为ALIVE的worker,并且随机打乱
    val shuffledAliveWorkers = Random.shuffle(workers.toSeq.filter(_.state == WorkerState.ALIVE))
	// 可用worker数量
    val numWorkersAlive = shuffledAliveWorkers.size
    var curPos = 0
	
// diriver调度过程(yarn-cluster模式下)
//yarn-cluster模式下才会注册driver，standalone和yarn-client模式下直接启动driver，而不会注册，就更不可能master调度driver了
    for (driver <- waitingDrivers.toList) { // iterate over a copy of waitingDrivers
      // We assign workers to each waiting driver in a round-robin fashion. For each driver, we
      // start from the last worker that was assigned a driver, and continue onwards until we have
      // explored all alive workers.
      var launched = false
      var numWorkersVisited = 0
	  // 判读还有可用的worker且Driver还未启动
      while (numWorkersVisited < numWorkersAlive && !launched) {
        val worker = shuffledAliveWorkers(curPos)
        numWorkersVisited += 1
		// 判断当前worker空闲内存是否大于等于driver需要的内存，且Worker空闲的core数量大于等于dirver需要的core的数量
        if (worker.memoryFree >= driver.desc.mem && worker.coresFree >= driver.desc.cores) {
		// 启动driver
          launchDriver(worker, driver)
          waitingDrivers -= driver
          launched = true
        }
		//指针指向下一个worker
        curPos = (curPos + 1) % numWorkersAlive
      }
    }

    // Right now this is a very simple FIFO scheduler. We keep trying to fit in the first app
    // in the queue, then the second app, etc.
	// application调度机制
    if (spreadOutApps) {
      // Try to spread out each app among all the nodes, until it has all its cores
	  // 遍历需要调度的app(Application),且该app中的core还需要调度
      for (app <- waitingApps if app.coresLeft > 0) {
	  //从worker中过滤出状态为ALIVE的，再次过滤能被Application使用的worker，在排序，按剩余cpu数量的倒序排序
        val usableWorkers = workers.toArray.filter(_.state == WorkerState.ALIVE)
          .filter(canUse(app, _)).sortBy(_.coresFree).reverse
		  //按照上面排序，可用worker的数量
        val numUsable = usableWorkers.length
		//为worker创建空数组，存储每个worker分配cpu的数量
        val assigned = new Array[Int](numUsable) // Number of cores to give on each node
		//取application所需cpu的数量和可用worker总共的cpu数量，两者最小值
        var toAssign = math.min(app.coresLeft, usableWorkers.map(_.coresFree).sum)
        var pos = 0
		//分配cpu，只要没有分配完，继续循环。
        while (toAssign > 0) {
		//空闲cpu数量大于已分配出去的cpu数量
          if (usableWorkers(pos).coresFree - assigned(pos) > 0) {
            toAssign -= 1//总分配数量减1
            assigned(pos) += 1//给这个worker分配数量加1
          }
		  //将指针移动到下一个worker
          pos = (pos + 1) % numUsable
        }
        // Now that we've decided how many cores to give on each node, let's actually give them
		//分配完cpu。遍历所有worker
        for (pos <- 0 until numUsable) {
		//这个worker是否被分配了cpu
          if (assigned(pos) > 0) {
		  // application创建一个ExecutorDesc
            val exec = app.addExecutor(usableWorkers(pos), assigned(pos))
            launchExecutor(usableWorkers(pos), exec)//在worker启动executor
            app.state = ApplicationState.RUNNING//application状态改为running
          }
        }
      }
    } else {
	//这个算法是 将application分配到尽可能少的worker上
      // Pack each app into as few nodes as possible until we've assigned all its cores
      for (worker <- workers if worker.coresFree > 0 && worker.state == WorkerState.ALIVE) {
        for (app <- waitingApps if app.coresLeft > 0) {
          if (canUse(app, worker)) {
            val coresToUse = math.min(worker.coresFree, app.coresLeft)
            if (coresToUse > 0) {
              val exec = app.addExecutor(worker, coresToUse)
              launchExecutor(worker, exec)
              app.state = ApplicationState.RUNNING
            }
          }
        }
      }
    }
  }

```

```scala
//某worker启动driver
  def launchDriver(worker: WorkerInfo, driver: DriverInfo) {
    logInfo("Launching driver " + driver.id + " on worker " + worker.id)
	//将driver加入worker的内部缓存结构
	//worker内增加driver要使用的cpu数量和内存空间
    worker.addDriver(driver)
	//同时把woker加入到driver的缓存结构中
    driver.worker = Some(worker)
	//worker发送消息，让worker启动driver
    worker.actor ! LaunchDriver(driver.id, driver.desc)
	//将driver的状态设置为running
    driver.state = DriverState.RUNNING
  }
```

```scala
  def canUse(app: ApplicationInfo, worker: WorkerInfo): Boolean = {
  //，worker剩余内存大于等于application对每个executor需要内存空间，并且worker没有启动executor
    worker.memoryFree >= app.desc.memoryPerSlave && !worker.hasExecutor(app)
  }
```
在application内部缓存结构中添加executor，并且创建ExecutorDesc对象，其中封装了，给executor分配多少个cpu core，在sprik1.3版本中通过spark-submit可以指定executor和cpu的数量以及内存数量，基于这种按中的cpu来分配的机制，最后executor的实际数量，以及每个executor的cpu可能与配置是不一样的，比如要求3个executor，每个要3个cpu，比如有9个worker，每个有一个cpu，那么其实总共要分配9个core，根据这种算法，会给每个worker分配一个core，然后每个worker启动一个executor最后会启动9个executor，每个executor有1个cpu core
```scala
  def addExecutor(worker: WorkerInfo, cores: Int, useID: Option[Int] = None): ExecutorDesc = {
    val exec = new ExecutorDesc(newExecutorId(useID), this, worker, cores, desc.memoryPerSlave)
    executors(exec.id) = exec
    coresGranted += cores
    exec
  }
```

```scala
  def launchExecutor(worker: WorkerInfo, exec: ExecutorDesc) {
    logInfo("Launching executor " + exec.fullId + " on worker " + worker.id)
    worker.addExecutor(exec)//executor加入worker内存的缓存
    worker.actor ! LaunchExecutor(masterUrl,
      exec.application.id, exec.id, exec.application.desc, exec.cores, exec.memory)
    exec.application.driver ! ExecutorAdded(
      exec.id, worker.id, worker.hostPort, exec.cores, exec.memory)
  }
```
## Worker原理与源码剖析
![13-17 ]()

``` scala
//org.apache.spark.deploy.worker
//Worker.scala
   case LaunchDriver(driverId, driverDesc) => {
      logInfo(s"Asked to launch driver $driverId")
      val driver = new DriverRunner(
        conf,
        driverId,
        workDir,
        sparkHome,
        driverDesc.copy(command = Worker.maybeUpdateSSLSettings(driverDesc.command, conf)),
        self,
        akkaUrl)
      drivers(driverId) = driver
      driver.start()

      coresUsed += driverDesc.cores
      memoryUsed += driverDesc.mem
    }
```
DriverRunner.scala中DriverRunner管理一个driver的执行，包括在driver失败时自动重启driver，这种方式紧紧使用在standalone模式中

```scala
//DriverRunner.scala
...
def start() = {
//启动一个Java线程
    new Thread("DriverRunner for " + driverId) {
      override def run() {
        try {
		//创建driver工作目录
          val driverDir = createWorkingDirectory()
		  //下载用户上传的Jar（Java，用maven打个jar包；scala，用export导出个jar包）
          val localJarFilename = downloadUserJar(driverDir)

          def substituteVariables(argument: String): String = argument match {
            case "{{WORKER_URL}}" => workerUrl
            case "{{USER_JAR}}" => localJarFilename
            case other => other
          }

          // TODO: If we add ability to submit multiple jars they should also be added here
		  //ProcessBuilder构建
		  //传入driver的启动命令，内存大小等信息
          val builder = CommandUtils.buildProcessBuilder(driverDesc.command, driverDesc.mem,
            sparkHome.getAbsolutePath, substituteVariables)
			//ProcessBuilder启动driver进程
          launchDriver(builder, driverDir, driverDesc.supervise)
        }
        catch {
          case e: Exception => finalException = Some(e)
        }

        val state =
          if (killed) {
            DriverState.KILLED
          } else if (finalException.isDefined) {
            DriverState.ERROR
          } else {
            finalExitCode match {
              case Some(0) => DriverState.FINISHED
              case _ => DriverState.FAILED
            }
          }

        finalState = Some(state)
//DriverRunner线程向其所属的worker的actor，发送DriverStateChanged的事件
        worker ! DriverStateChanged(driverId, state, finalException)
      }
    }.start()
  }
...
```
downloadUserJar
```scala
 private def downloadUserJar(driverDir: File): String = {
//用hadoop jar里的Path
    val jarPath = new Path(driverDesc.jarUrl)
//拿到hadoop配置
    val hadoopConf = SparkHadoopUtil.get.newConfiguration(conf)
	//获取HDFS的FileSystem
    val jarFileSystem = jarPath.getFileSystem(hadoopConf)
//创建本地目录
    val destPath = new File(driverDir.getAbsolutePath, jarPath.getName)
    val jarFileName = jarPath.getName
    val localJarFile = new File(driverDir, jarFileName)
    val localJarFilename = localJarFile.getAbsolutePath

    if (!localJarFile.exists()) { // May already exist if running multiple workers on one node
      logInfo(s"Copying user jar $jarPath to $destPath")
	  //FileUtil的jar包copy到本地
      FileUtil.copy(jarFileSystem, jarPath, destPath, false, hadoopConf)
    }
	
	    if (!localJarFile.exists()) { // Verify copy succeeded
      throw new Exception(s"Did not see expected jar $jarFileName in $driverDir")
   			 }

    localJarFilename
```

总结

1、Worker、Driver、Application启动后都会向Master进行注册,并缓存到Master内存数据模型中
2、完成注册后发送LaunchExecutor、LaunchDriver到Worker
3、Worker收到消息后启动executor和driver进程，并调用Worker的ExecutorStateChanged和DriverStateChanged方法
4、发送ExecutorStateChanged和DriverStateChanged消息到Master的，根据各自的状态信息进行处理，最重要的是会调用schedule方法进行资源的重新调度